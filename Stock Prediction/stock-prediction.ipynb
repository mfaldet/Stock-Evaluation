{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas_datareader as pdr\n",
    "\n",
    "# Define the instruments to download. We would like to see Apple, Microsoft and the S&P500 index.\n",
    "tickers = ['GOOG', 'MSFT', 'SPY']\n",
    "\n",
    "# We would like all available data from 01/01/2000 until 12/31/2016.\n",
    "start_date = '2012-10-01'\n",
    "end_date = '2022-10-01'\n",
    "\n",
    "#df = yf.Ticker('goog').history(interval='15m', start='2012-09-10', end='2022-09-10')\n",
    "df = pdr.DataReader(tickers, 'yahoo', start_date, end_date)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting just the adjusted closing prices. This will return a Pandas DataFrame\n",
    "# The index in this DataFrame is the major index of the panel_data.\n",
    "close = df['Close']\n",
    "\n",
    "# Getting all weekdays between 01/01/2000 and 12/31/2016\n",
    "all_weekdays = pd.date_range(start=start_date, end=end_date, freq='B')\n",
    "\n",
    "# How do we align the existing prices in adj_close with our new set of dates?\n",
    "# All we need to do is reindex close using all_weekdays as the new index\n",
    "close = close.reindex(all_weekdays)\n",
    "\n",
    "# Reindexing will insert missing values (NaN) for the dates that were not present\n",
    "# in the original set. To cope with this, we can fill the missing by replacing them\n",
    "# with the latest available price for each instrument.\n",
    "close = close.fillna(method='ffill')\n",
    "\n",
    "close.dropna(inplace=True)\n",
    "close.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_equity(df, index):\n",
    "    # Get the MSFT timeseries. This now returns a Pandas Series object indexed by date.\n",
    "    idx = df.loc[:, index]\n",
    "\n",
    "    # Calculate the 20 and 100 days moving averages of the closing prices\n",
    "    short_rolling_idx = idx.rolling(window=20).mean()\n",
    "    long_rolling_idx = idx.rolling(window=100).mean()\n",
    "\n",
    "    # Plot everything by leveraging the very powerful matplotlib package\n",
    "    fig, ax = plt.subplots(figsize=(16,9))\n",
    "\n",
    "    ax.plot(idx.index, idx, label=index)\n",
    "    ax.plot(short_rolling_idx.index, short_rolling_idx, label='20 days rolling')\n",
    "    ax.plot(long_rolling_idx.index, long_rolling_idx, label='100 days rolling')\n",
    "\n",
    "    ax.set_xlabel('Date')\n",
    "    ax.set_ylabel('Adjusted closing price ($)')\n",
    "    ax.legend()\n",
    "    plt.show()\n",
    "\n",
    "visualize_equity(close, 'MSFT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_equity(close, 'GOOG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_equity(close, 'SPY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=close.copy()\n",
    "\n",
    "# Identify dates as datetimes\n",
    "def str_to_datetime(s):\n",
    "        import datetime\n",
    "        split = s.split('-')\n",
    "        year, month, day = int(split[0]), int(split[1]), int(split[2])\n",
    "        return datetime.datetime(year=year, month=month, day=day)\n",
    "\n",
    "if (data.index.dtype != '' and data.index.dtype != 'datetime64[ns]'):\n",
    "    data.reset_index(inplace=True)\n",
    "    data['Date'] = df['Date'].apply(str_to_datetime)\n",
    "else: \n",
    "    print('Date is already Datetime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "close['MSFT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start day second time around: '2021-03-25'\n",
    "df=pd.DataFrame(close['MSFT'])\n",
    "X_timesteps=3\n",
    "start_date='2017-10-01'\n",
    "end_date='2022-10-01'\n",
    "\n",
    "# Phrase the data as the info considered in a daily window of time\n",
    "def df_to_windowed_df(dataframe, first_date_str, last_date_str, n=3):\n",
    "    # n is the number of timesteps (X)\n",
    "    import numpy as np\n",
    "    first_date = str_to_datetime(first_date_str)\n",
    "    last_date  = str_to_datetime(last_date_str)\n",
    "\n",
    "    target_date = first_date\n",
    "\n",
    "    dates = []\n",
    "    X, Y = [], []\n",
    "\n",
    "    last_time = False\n",
    "    while True:\n",
    "        df_subset = dataframe.loc[:target_date].tail(n+1)\n",
    "\n",
    "        if len(df_subset) != n+1:\n",
    "            print(f'Error: Window of size {n} is too large for date {target_date}')\n",
    "            return\n",
    "\n",
    "        values = df_subset['Close'].to_numpy()\n",
    "        x, y = values[:-1], values[-1]\n",
    "\n",
    "        dates.append(target_date)\n",
    "        X.append(x)\n",
    "        Y.append(y)\n",
    "\n",
    "        next_week = dataframe.loc[target_date:target_date+datetime.timedelta(days=7)]\n",
    "        next_datetime_str = str(next_week.head(2).tail(1).index.values[0])\n",
    "        next_date_str = next_datetime_str.split('T')[0]\n",
    "        year_month_day = next_date_str.split('-')\n",
    "        year, month, day = year_month_day\n",
    "        next_date = datetime.datetime(day=int(day), month=int(month), year=int(year))\n",
    "\n",
    "        if last_time:\n",
    "            break\n",
    "\n",
    "        target_date = next_date\n",
    "\n",
    "        if target_date == last_date:\n",
    "            last_time = True\n",
    "\n",
    "    ret_df = pd.DataFrame({})\n",
    "    ret_df['Target Date'] = dates\n",
    "\n",
    "    X = np.array(X)\n",
    "    for i in range(0, n):\n",
    "        X[:, i]\n",
    "        ret_df[f'Target-{n-i}'] = X[:, i]\n",
    "\n",
    "    ret_df['Target'] = Y\n",
    "\n",
    "    return ret_df\n",
    "\n",
    "windowed_df = df_to_windowed_df(df,start_date,end_date,n=X_timesteps)\n",
    "windowed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splits the df into three cruicial tensor components: (the date, input, target)\n",
    "def windowed_df_to_date_X_y(windowed_dataframe, number_of_y_vars=1):\n",
    "    df_as_np = windowed_dataframe.to_numpy()\n",
    "\n",
    "    dates = df_as_np[:, 0] #dates kept in first column, not as index\n",
    "\n",
    "    middle_matrix = df_as_np[:, 1:-number_of_y_vars] #all x (after dates, before y)\n",
    "    X = middle_matrix.reshape((len(dates), middle_matrix.shape[1], number_of_y_vars))\n",
    "\n",
    "    Y = df_as_np[:, -number_of_y_vars:]\n",
    "\n",
    "    return dates, X.astype(np.float32), Y.astype(np.float32)\n",
    "\n",
    "dates, X, y = windowed_df_to_date_X_y(windowed_df)\n",
    "\n",
    "dates.shape, X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split for 80% train, 10% validation, 10% test\n",
    "q_80 = int(len(dates) * .8)\n",
    "q_90 = int(len(dates) * .9)\n",
    "\n",
    "dates_train, X_train, y_train = dates[:q_80], X[:q_80], y[:q_80]\n",
    "\n",
    "dates_val, X_val, y_val = dates[q_80:q_90], X[q_80:q_90], y[q_80:q_90]\n",
    "dates_test, X_test, y_test = dates[q_90:], X[q_90:], y[q_90:]\n",
    "\n",
    "plt.plot(dates_train, y_train)\n",
    "plt.plot(dates_val, y_val)\n",
    "plt.plot(dates_test, y_test)\n",
    "\n",
    "plt.legend(['Train', 'Validation', 'Test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "model = Sequential([layers.Input((3, 1)),\n",
    "                    layers.LSTM(64),\n",
    "                    layers.Dense(32, activation='relu'),\n",
    "                    layers.Dense(32, activation='relu'),\n",
    "                    layers.Dense(1)])\n",
    "\n",
    "model.compile(loss='mse',  \n",
    "                optimizer=Adam(learning_rate=0.001), \n",
    "                metrics=['mean_absolute_error','root_mean_squared_error'])\n",
    "\n",
    "model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predictions = model.predict(X_train).flatten()\n",
    "\n",
    "plt.plot(dates_train, train_predictions)\n",
    "plt.plot(dates_train, y_train)\n",
    "plt.legend(['Training Predictions', 'Training Observations'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_predictions = model.predict(X_val).flatten()\n",
    "\n",
    "plt.plot(dates_val, val_predictions)\n",
    "plt.plot(dates_val, y_val)\n",
    "plt.legend(['Validation Predictions', 'Validation Observations'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = model.predict(X_test).flatten()\n",
    "\n",
    "plt.plot(dates_test, test_predictions)\n",
    "plt.plot(dates_test, y_test)\n",
    "plt.legend(['Testing Predictions', 'Testing Observations'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(dates_train, train_predictions)\n",
    "plt.plot(dates_train, y_train)\n",
    "plt.plot(dates_val, val_predictions)\n",
    "plt.plot(dates_val, y_val)\n",
    "plt.plot(dates_test, test_predictions)\n",
    "plt.plot(dates_test, y_test)\n",
    "plt.legend(['Training Predictions', \n",
    "            'Training Observations',\n",
    "            'Validation Predictions', \n",
    "            'Validation Observations',\n",
    "            'Testing Predictions', \n",
    "            'Testing Observations'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('Dev')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4914ba6a01d5cc2a20b86037113efe1eba6c9cdc0067719a22bf848a5c26a91a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
